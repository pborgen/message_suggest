PORT=8080

# local engine: llamacpp | mock
LOCAL_ENGINE=llamacpp

# llama.cpp server (run separately)
LLAMACPP_URL=http://localhost:8081/completion
